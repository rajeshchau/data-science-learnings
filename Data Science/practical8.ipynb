{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## practical 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rc880\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "  label                                            message\n",
      "0   ham  go jurong point crazy available bugis great wo...\n",
      "1   ham                              ok lar joking wif oni\n",
      "2  spam  free entry wkly comp win fa cup final tkts st ...\n",
      "3   ham                  u dun say early hor c already say\n",
      "4   ham             nah think goes usf lives around though\n",
      "Accuracy: 0.98\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1448\n",
      "        spam       1.00      0.87      0.93       224\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.99      0.93      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the dataset\n",
    "# If you have the dataset as a text file named 'SMSSpamCollection', use the following:\n",
    "# df = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label', 'message'])\n",
    "\n",
    "# Or download it using pandas directly (assuming it is hosted online).\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "df = pd.read_csv('SMSSpamCollection.csv', sep='\\t', names=['label', 'message'])\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "# Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    # Remove single characters\n",
    "\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the messages\n",
    "df['message'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "# Display some processed messages\n",
    "print(df.head())\n",
    "\n",
    "# Convert labels to binary (1 for spam, 0 for ham)\n",
    "df['label'] = df['label'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# Feature extraction using TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "X = tfidf.fit_transform(df['message']).toarray()\n",
    "y = df['label'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['ham', 'spam'])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"\\nClassification Report:\\n{report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
